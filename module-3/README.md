# Module 3: Working with Terraform modules

# The Challenge

In the previous module you have hardened your virtual machine and made your template more reusable. Terraform is all about templates and reusability. For almost all imagineable cloud resources, and even whole reference architectures, there are templates (or **Modules** in Terraform) available in the [Terraform registry](https://registry.terraform.io/browse/modules).

In this module, we will continue working on our previous work. If you have not completed the previous module, you can use the full code example in the [full_solution folder in module-2](../module-2/full_solution).
The ultimate goal is to turn your Terraform code into a module and deploy it for re-use. You will also work with remote state backends, so you are fully ready to start deploying your work in the cloud!

> Assignments are marked like this.

<details>
<summary>Solutions are shown like this.</summary>
    Hi! Only open these when you are completely clueless.
</details>
<p></p>

And you can also earn **Bonus points**! These are not included in the full solution, so it's fully up to you on how you solve these challenges!

See how far you can get during the workshop:

- **Level 1: Use functions to dynamically generate resources/properties**
- **Level 2: Store state in a remote backend**
- **Level 3: Work with modules in your Terraform configuration**
- **Level 4: Turn your code into a reusable module**

Some general tips before you start:

- With Terraform, you basically create a template to deploy infrastructure. This means that a lot of examples are available all over the internet. You can often find a module or template that allows you to only fill out some variables in order to deploy a resource that matches your needs.
- Think of Terraform as an API layer for the Azure API itself. Any option you see in the Azure portal, or remember from your work, has an equivalent property in the corresponding resource. So if you are lost, go to the portal and try creating a resource manually. The properties you see there reflect the properties you can set for that resource in Terraform. Just use the [provider documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs) to find out the name of the property for that resource.
- Always run `terraform plan` before you run `terraform apply`. Terraform will clearly show you the impact your code changes will have on the real world infrastructure. You can experiment all you want if you use `plan`.
- Check out [this](https://www.tfwriter.com/azurerm/azurerm.html) awesome website to grab some autogenerated Terraform code. If you are ever in need of some prefabricated code for creating a resource, variable or output you can get it here. This one is for the advanced users, but once you find out how useful it is you keep coming back!
- If you run into any issues anywhere, just run `terraform destroy` and `terraform apply` again. The beauty of declarative languages is you get exactly the same infrastructure back the way you wrote it in your code :)
  
## Level 1: Use functions to dynamically generate resources/properties

While Terraform is not technically a programming language, there are several built-in functions you can use to generate dynamically generate properties or resources. These functions allow string manipulation, collections, logical functions and much more. Read more about them [here](https://www.terraform.io/language/functions). You have already worked with a few functions in the previous modules, such as the `regex` function to validate variable values or the `formatdate` function to generate a specific timestamp format. We will work with some common functions in the upcoming excercises.

> Let's start simple. Use a string manipulation feature to remove the dashes ('-') from `local.rootname` to generate `local.trimmed_rootname`.

<details>
<summary>Solution</summary>

```hcl
# main.tf
locals {
  rootname         = "bctf-${var.yourname}-${var.location}"
  trimmed_rootname = replace(local.rootname, "-", "")
...
```

</details>

Run `terraform plan` and verify this changes nothing to your configuration, but it makes your code a little bit nicer.<p>
We are currently defining our tags in the `local.tags` block so they can be the same for all resources we deploy. But what if we want to allow users of our template to specify additional custom tags, or we want to have additional tags for specific resources?

> Create a variable definition called `additional_tags` (use the correct type!) and ensure that it is added to all resources we create using the same `locals.tags` block. Add a custom `key=value` tag to your `.tfvars` file. Run `terraform plan` to ensure all your resources are being **changed**.

<details>
<summary>Solution</summary>

```hcl
# variables.tf
variable "additional_tags" {
  description = "A list of additional tags that can be added to the centralized tags block"

  type    = map(string)
  default = {}
}

# terraform.tfvars
additional_tags = {
  "MyTerraformSkillLevel" = "Uberhigh"
}

# main.tf
locals {
  ...
  tags = merge({
      "costCenter" = "BrightCubesInternal"
      "owner"      = var.yourname
      "region"     = var.location
    }, var.additional_tags
  )
}
```

</details>

There may also be cases where you want to add parameters to your template that you want to have visible somewhere. An example we will explore here is the VM shutdown schedule. You may want to let the user configure this shutdown schedule, but also show it in the tags on the Overview pane of your virtual machine in the Azure Portal to make it clear this is configured.<p>

> First find the way Terraform configures the automated shutdown schedules for Azure VMs. Next, create two variable definitions called `vm_shutdown_time` and `enable_auto_shutdown`. Add these variables to the shutdown schedule resource and add both variables to the tags of your Azure VM as a string in a `key=value` pair.

**Bonus points**: Create a variable validation rule to validate that the value inputted to the `vm_shutdown_time` variable is of the format Terraform expects for that specific property argument.

<details>
<summary>Solution</summary>

```hcl
# variables.tf
variable "vm_shutdown_time" {
  type = number
}

variable "enable_vm_shutdown" {
  type = bool
}

# terraform.tfvars
enable_vm_shutdown = true
vm_shutdown_time   = 2000

# main.tf
resource "azurerm_dev_test_global_vm_shutdown_schedule" "bctf-vm-shutdown" {
  virtual_machine_id = azurerm_linux_virtual_machine.bctf-vm.name
  location           = var.location
  enabled            = var.enable_vm_shutdown

  daily_recurrence_time = var.vm_shutdown_time
  timezone              = "W. Europe Standard Time"

  notification_settings {
    enabled = false
  }
}

resource "azurerm_linux_virtual_machine" "bctf-vm" {
  ...
  tags = merge(
    local.tags,
    { "enable_vm_shutdown" = tostring(var.enable_vm_shutdown) },
    { "vm_shutdown_time" = tostring(var.vm_shutdown_time) }
  )
  ...
```

</details>

Go to your virtual machine in the Azure Portal and verify that your tags contain your custom `additional_tag`, the values you have set for the variables and that your shutdown schedule is correctly configured under 'Auto-shutdown' in the left navigation pane.<p>
As you've noticed, some resources allow you to conditionally enable their creation through a property argument (`enabled = true`). However, this is not the case for most Terraform resources. They way you normally deal with conditional resources is through the `count` or `for_each` arguments. Read more about them [here](https://www.terraform.io/language/meta-arguments/count). While this may sometimes feel illogical, you can use this argument to create anywhere between *0* and *n* instances of a resource, and in this case `count = 0` basically tells Terraform to not create any instance of the resource. Think of `count` as a simple looping mechanism, while `for_each` gives you a few more options.

Let's go ahead and try this out. Imagine we want to give the user of our template the option to conditionally attach a data disk to our VM to increase storage space. In this example we do not worry about attaching the disk in the OS itself, just adding it within Azure.

> First create a boolean variable definition that allows the user to specify if they want to attach a data disk. Use a size of 128GB and type `Standard_LRS`. Next, find the way that Terraform allows you to first create and then attach data disks to a virtual machine (using two separate resources). Use the `count` argument to conditionally create `1` or `0` instances of both resources by evaluating the value passed to your newly created boolean.

**Bonus points**: Create an **implicit** dependency from your new data disk on the Azure VM resource through its `name` property, by using your VM's name in the name of your disk.

<details>
<summary>Solution</summary>

```hcl
# variables.tf
variable "add_data_disk" {
  type = bool  
}

# terraform.tfvars
add_data_disk = true

# main.tf
resource "azurerm_managed_disk" "bctf-vm-datadisk" {
  count                = var.add_data_disk ? 1 : 0
  name                 = "${azurerm_linux_virtual_machine.bctf-vm.name}-datadisk"
  location             = var.location
  resource_group_name  = azurerm_resource_group.bctf-rg.name
  storage_account_type = "Standard_LRS"
  disk_size_gb         = 128
  create_option        = "Empty"
}

resource "azurerm_virtual_machine_data_disk_attachment" "bctf-vm-datadisk-attach" {
  count              = var.add_data_disk ? 1 : 0
  managed_disk_id    = azurerm_managed_disk.bctf-vm-datadisk[count.index].id
  virtual_machine_id = azurerm_linux_virtual_machine.bctf-vm.id
  lun                = "10"
  caching            = "ReadWrite"
}
```

</details>

Go to your virtual machine in the Azure Portal and verify that your disk has been added successfully 'Disks' in the left navigation pane.<p>
As you can see, you can use this `count` property to dynamically create a resource. This gives you a lot of possibilities. Another example that Terraform presents [here](https://learn.hashicorp.com/tutorials/terraform/expressions?in=terraform/configuration-language#create-a-conditional-count-criteria) is that by declaring a variable called `var.high_availability` you can dynamically create 1 or 3 instances of a VM or workload based on the way you set your variables. Or you can use a `var.osType` variable when you have both a `azurerm_linux_virtual_machine` and a `azurerm_windows_virtual_machine` in your template to dynamically create 1 or 0 instances of each.<p>
But what if you want to add more options for configuring these disks, for example by specifying the size or storage account type for any number of disks? You would have to create multiple variables for a fixed amount of disks, like `var.disk1sku` and `var.disk2size`. This is where `for_each` can help you specify more complex types without duplicating too much code.

> First, create a complex variable that contains a map of objects containing the disk name, size and type. Add two different data disks (just identify them by `1` and `2`) of different names and sizes through your `.tfvars` file by passing them as a map to this object. Finally adjust the two resources you created in the previous exercise in `main.tf` to reflect your changes using the `for_each` argument instead of `count`.<p>
> You will run into issues with your LUN. This needs to be identical for each disk. There are multiple ways to fix this so it's up to you! <p>
<details>
<summary>Hint for the LUN part</summary>
You can solve this by adding them to your `map` or by using a random ID or by using the `1` or `2` map identifiers through `each.key`.
</details>

<details>
<summary>Solution</summary>

```hcl
# variables.tf
variable "data_disks" {
  description = "Allows you to specify a map of configurations for multiple data disks. To not create any data disks, use 'data_disks={}' in your tfvars."
  
  type = map(object({
    name = string
    size = number
  }))
}

# terraform.tfvars
data_disks = {
    1 = {
      name = "smalldatadisk"
      size = 128
    },
    2 = {
      name = "bigdatadisk"
      size = 256
    }
}

# main.tf
resource "azurerm_managed_disk" "bctf-vm-datadisk" {
  for_each = var.data_disks
  
  name                 = each.value.name
  location             = var.location
  resource_group_name  = azurerm_resource_group.bctf-rg.name
  storage_account_type = "Standard_LRS"
  disk_size_gb         = each.value.size
  create_option        = "Empty"
}

resource "azurerm_virtual_machine_data_disk_attachment" "bctf-vm-datadisk-attach" {
  for_each = var.data_disks
  
  managed_disk_id    = azurerm_managed_disk.bctf-vm-datadisk[each.key].id
  virtual_machine_id = azurerm_linux_virtual_machine.bctf-vm.id
  lun                = 10 + each.key
  caching            = "ReadWrite"
}
```

</details>

There are many more functions and arguments to experiment with, but this should give you a sneak peek into what is possible with Terraform.

## Level 2: Store state in a remote backend

By default, Terraform stores state locally in a file named terraform.tfstate. When working with Terraform in a team, use of a local file makes Terraform usage complicated because each user must make sure they always have the latest state data before running Terraform and make sure that nobody else runs Terraform at the same time, since Terraform locks the file during its operations.

With remote state, Terraform writes the state data to a remote data store, which can then be shared between all members of a team. Terraform supports storing state in Terraform Cloud, HashiCorp Consul, Amazon S3, Azure Blob Storage, Google Cloud Storage, Alibaba Cloud OSS, and more. The place where the state is stored by Terraform is called a `backend`.

By default, Terraform uses a backend called local, which stores state as a local file on disk. But in any use case where you are not the only person using the Terraform infrastructure, you should always configure a Terraform backend. In this module, we will configure an `azurerm` backend and store our Terraform state in an Azure storage account. Since the state file contains sensitive data that should be protected, we will prevent a meta situation where we store the Terraform state file in the same storage account as the one we create with our Terraform code. You should make sure that the storage account you use for Terraform state files is well protected. In this workshop we will use a pre-created storage account and storage container.

> Create a file `backend.tf` containing an `azurerm` backend configuration. The storage account name is `bcworkshoptfstates` in resource group `bctf-workshop-rg` and the container name is `tfstates`. You can think of your own `key` (filename) and you can just use your Azure CLI authentication mechanism. Run `terraform init` again to initialize the new backend configuration.

<details>
<summary>Solution</summary>

```hcl
# backend.tf
terraform {
  backend "azurerm" {
    resource_group_name  = "bctf-workshop-rg"
    storage_account_name = "bcworkshoptfstates"
    container_name       = "tfstates"
    key                  = "tommy.terraform.tfstate"
  }
}
```
</details>

You will be asked if you want to copy the existing state file. Enter "yes" since we do want to migrate from a local to a remote backend! Check the contents of your local `terraform.tfstate` file and verify that the file is now empty, since we've moved this state file to the storage account.

In most CI/CD scenarios you will use service principals or Azure CLI to authenticate to an `azurerm` backend. However, you can also specify any of the lines in the backend configuration as a command-line parameter or through a separate file, after with you can pass them to the `terraform init` command using `-backend-config=PATH` (for files) or `-backend-config="KEY=VALUE"` for inline variables, such as `-backend-config="access_key=$SUPERSECRETKEY_IN_MY_DEVOPS_RUNNER"`.

## Level 3: Work with modules in your Terraform configuration

As mentioned before, modules are reusable pieces of Terraform code. In the [Terraform registry](https://registry.terraform.io/browse/modules?provider=azurerm) there are a huge amount of modules available for use in your Terraform code. You can use these, but also use any Git-based or path-based reference to a folder containing Terraform code. In the next exercises, we will work with public (Git) modules, and later turn our own Terraform configuration into a module and reference to it based on its path.

Let's change our configuration a bit. We are currently using an existing virtual network referencing a `data` source, but let's create our own virtual network and subnets using the official Azure VNet module that is maintained by Microsoft.

> Find the Azure/vnet module in the Terraform Registry. Check out the code for the module on GitHub to see how it works. Replace the virtual network and subnet resource in our `main.tf` with a `module` block. Add a second subnet. Be sure to change the `address_space` and `subnet_prefixes`. Assign the network security group we created earlier to both subnets. Also add our tags block. Make sure you update the existing references to the virtual network and subnet to reflect the `output` values of the module.

<details>
<summary>Solution</summary>

```hcl
module "azure-vnet" {
  source              = "Azure/vnet/azurerm"

  vnet_name           = "${local.rootname}-vnet"
  resource_group_name = azurerm_resource_group.bctf-rg.name
  address_space       = ["10.5.0.0/16"]
  subnet_prefixes     = ["10.5.90.0/24", "10.5.100.0/24"]
  subnet_names        = ["subnet1", "subnet2"]

  subnet_service_endpoints = {
    subnet1 = ["Microsoft.Storage", "Microsoft.Sql", "Microsoft.KeyVault"]
    subnet2 = ["Microsoft.KeyVault"]
  }

  nsg_ids = {
    subnet1 = azurerm_network_security_group.bctf-nsg.id
    subnet2 = azurerm_network_security_group.bctf-nsg.id
  }

  tags = local.tags
}

resource "azurerm_network_interface" "bctf-nic" {
...
  ip_configuration {
    name                          = "${local.rootname}-nic-cfg"
    subnet_id                     = module.azure-vnet.vnet_subnets[0]
...

resource "azurerm_key_vault" "bctf-kv" {
...
  network_acls {
    default_action             = "Deny"
    bypass                     = "AzureServices"
    virtual_network_subnet_ids = module.azure-vnet.vnet_subnets
    ip_rules                   = ["${var.my_ip_address}"] # Your own IP address
  }
...
```
</details>

**NOTE:** You will probably run into some issues with your NIC and the virtual machine not being able to handle the removal of your existing subnet. For the sake of this workshop you can choose to keep them to prevent the errors, or you can use `terraform taint` to force recreation of the NIC and the VM when you run `terraform apply` next.

Let's move on to the next part and start preparing our code for turning it into a module!

## Level 4: Turn your code into a reusable module

As you start working with Terraform more and more, you will start re-using a lot of different templates. Think of situations where you want to separate environments or share templates with your colleagues. Instead of sharing your Terraform code, you can also turn your templates into modules. Hashicorp mentions a number of advantages in their documentation [here](https://learn.hashicorp.com/tutorials/terraform/module?in=terraform/modules):

- Organize configuration - Modules make it easier to navigate, understand, and update your configuration by keeping related parts of your configuration together. Even moderately complex infrastructure can require hundreds or thousands of lines of configuration to implement. By using modules, you can organize your configuration into logical components.

- Encapsulate configuration - Another benefit of using modules is to encapsulate configuration into distinct logical components. Encapsulation can help prevent unintended consequences, such as a change to one part of your configuration accidentally causing changes to other infrastructure, and reduce the chances of simple errors like using the same name for two different resources.

- Re-use configuration - Writing all of your configuration from scratch can be time consuming and error prone. Using modules can save time and reduce costly errors by re-using configuration written either by yourself, other members of your team, or other Terraform practitioners who have published modules for you to use. You can also share modules that you have written with your team or the general public, giving them the benefit of your hard work.

- Provide consistency and ensure best practices - Modules also help to provide consistency in your configurations. Not only does consistency make complex configurations easier to understand, it also helps to ensure that best practices are applied across all of your configuration. For instance, cloud providers give many options for configuring object storage services, such as Amazon S3 or Google Cloud Storage buckets. There have been many high-profile security incidents involving incorrectly secured object storage, and given the number of complex configuration options involved, it's easy to accidentally misconfigure these services.

Using modules can help reduce these errors. For example, you might create a module to describe how all of your organization's public website buckets will be configured, and another module for private buckets used for logging applications. Also, if a configuration for a type of resource needs to be updated, using modules allows you to make that update in a single place and have it be applied to all cases where you use that module.

